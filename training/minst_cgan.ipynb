{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY0-8_rA9Pze"
      },
      "source": [
        "Following https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TREZ-IDf84to"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy import concatenate\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Concatenate\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "from keras import backend\n",
        "\n",
        "import psutil\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVVFLN5k92AI"
      },
      "outputs": [],
      "source": [
        "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n",
        "\tin_label = Input(shape=(1,))\n",
        "\tli = Embedding(n_classes, 50)(in_label)\n",
        "\tn_nodes = in_shape[0] * in_shape[1]\n",
        "\tli = Dense(n_nodes)(li)\n",
        "\tli = Reshape((in_shape[0], in_shape[1], 1))(li)\n",
        "\tin_image = Input(shape=in_shape)\n",
        "\tmerge = Concatenate()([in_image, li])\n",
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
        "\tfe = Flatten()(fe)\n",
        "\tfe = Dropout(0.4)(fe)\n",
        "\tout_layer = Dense(1, activation='sigmoid')(fe)\n",
        "\tmodel = Model([in_image, in_label], out_layer)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2wAh8M9U8n6"
      },
      "outputs": [],
      "source": [
        "discriminator = define_discriminator()\n",
        "discriminator.summary()\n",
        "plot_model(discriminator, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRXKg72-TSp"
      },
      "outputs": [],
      "source": [
        "def define_generator(latent_dim, n_classes=10):\n",
        "\tin_label = Input(shape=(1,))\n",
        "\tli = Embedding(n_classes, 50)(in_label)\n",
        "\tn_nodes = 7 * 7\n",
        "\tli = Dense(n_nodes)(li)\n",
        "\tli = Reshape((7, 7, 1))(li)\n",
        "\tin_lat = Input(shape=(latent_dim,))\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tgen = Dense(n_nodes)(in_lat)\n",
        "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
        "\tgen = Reshape((7, 7, 128))(gen)\n",
        "\tmerge = Concatenate()([gen, li])\n",
        "\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
        "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
        "\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
        "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
        "\tout_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
        "\tmodel = Model([in_lat, in_label], out_layer)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjqj4io1VRyb"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "generator = define_generator(latent_dim)\n",
        "generator.summary()\n",
        "plot_model(generator, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkGPWSLb-WEi"
      },
      "outputs": [],
      "source": [
        "def define_gan(g_model, d_model):\n",
        "\td_model.trainable = False\n",
        "\tgen_noise, gen_label = g_model.input\n",
        "\tgen_output = g_model.output\n",
        "\tgan_output = d_model([gen_output, gen_label])\n",
        "\tmodel = Model([gen_noise, gen_label], gan_output)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "model = define_gan(generator, discriminator)\n",
        "model.summary()\n",
        "plot_model(model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTrjAM4n-ZLA"
      },
      "outputs": [],
      "source": [
        "def load_real_samples():\n",
        " (trainX, trainy), (testX, testY) = load_data()\n",
        " x = concatenate((trainX, testX), axis=0)\n",
        " y = concatenate((trainy, testY), axis=0)\n",
        " X = expand_dims(x, axis=-1)\n",
        " X = X.astype('float32')\n",
        " X = X / 255\n",
        " return [X, y]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jIXDbTX-bsu"
      },
      "outputs": [],
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "\timages, labels = dataset\n",
        "\tix = randint(0, images.shape[0], n_samples)\n",
        "\tX, labels = images[ix], labels[ix]\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn [X, labels], y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGRFHORX-eyD"
      },
      "outputs": [],
      "source": [
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\tlabels = randint(0, n_classes, n_samples)\n",
        "\treturn [z_input, labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVRjsMyQ-iNe"
      },
      "outputs": [],
      "source": [
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\tz_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "\timages = generator.predict([z_input, labels_input])\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn [images, labels_input], y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f_YCJV9_2g_"
      },
      "outputs": [],
      "source": [
        "def show_progress(model, n):\n",
        "  latent_points, labels = generate_latent_points(100, 100)\n",
        "  labels = asarray([x for _ in range(10) for x in range(10)])\n",
        "  examples  = model.predict([latent_points, labels])\n",
        "  for i in range(n * n):\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "  pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSXVzBW_DR8T"
      },
      "outputs": [],
      "source": [
        "def free_space():\n",
        "  memory_before = psutil.virtual_memory().used\n",
        "  backend.clear_session()\n",
        "  gc.collect()\n",
        "  print(\"reclaimed memory: \"+ str(psutil.virtual_memory().used - memory_before))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsFVGMQb-lRm"
      },
      "outputs": [],
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n",
        "\tbat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\tfor i in range(n_epochs):\n",
        "\t\tfor j in range(bat_per_epo):\n",
        "\t\t\t[X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\td_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
        "\t\t\t[X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\td_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
        "\t\t\t[z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t\tg_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
        "\t\t\tprint('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "\t\tshow_progress(g_model, 10)\n",
        "\t\tfree_space()\n",
        "\t\tg_model.save('cgan_generator.h5')\n",
        "\t\td_model.save('cgan_discriminator.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4s7KDuI-oYl"
      },
      "outputs": [],
      "source": [
        "latent_dim = 100\n",
        "discriminator = define_discriminator()\n",
        "generator = define_generator(latent_dim)\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "dataset = load_real_samples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RolSgeiEAL2D"
      },
      "outputs": [],
      "source": [
        "train(generator, discriminator, gan_model, dataset, latent_dim)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
